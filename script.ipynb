{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fc751\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from scipy import sparse\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = './data/'\n",
    "#train = pd.read_table(path+\"round1_ijcai_18_train_20180301.txt\",sep=\" \")\n",
    "#test = pd.read_table(path+'round1_ijcai_18_test_a_20180301.txt',sep=\" \")\n",
    "#data = train.append(test, ignore_index=True)\n",
    "#data.sort_values(by='context_timestamp') #时间戳排序\n",
    "#train = pd.read_csv(path+\"2train.csv\")\n",
    "#test = pd.read_csv(path+\"2test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./data/train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8cb10623c7cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min_lab'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hour'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'minute'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'min_lab'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmin_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_lab'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'instance_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'min_query'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'./data/train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\")\n",
    "data['min_lab'] = data['hour'] * 60 + data['minute']\n",
    "data.sort_values(by=['user_id','min_lab'])\n",
    "min_query = data.groupby(['user_id', 'min_lab'], as_index=False)['instance_id'].agg({'min_query': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['user_gender_id', 'item_brand_id', 'day'], as_index=False)['hour'].agg({'user_day_hour_item_var': 'var'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[['instance_id','item_id']].loc[data.hour>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"./submit/lgb_feat_imp.csv\")\n",
    "low = sub.loc[sub.score<20]\n",
    "low.sort_values('feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = sub.loc[(sub.score>=0)&(sub.score<=200)]\n",
    "#low.sort_values('feature')\n",
    "low.loc[low.feature=='click_user_city_lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling(df,roll,window):\n",
    "    last=roll(df,window=window).tolist()\n",
    "    last=[np.NaN]+last\n",
    "    last.pop()\n",
    "    return last\n",
    "uid = min_query['user_id'].unique().tolist()\n",
    "new = pd.DataFrame()\n",
    "for u in uid:\n",
    "    print(u)\n",
    "    df = min_query[min_query['user_id'] == u]\n",
    "    df['last_1_sum_user'] = rolling(df['min_query'], pd.rolling_sum, window=1)\n",
    "    df['last_3_sum_user'] = rolling(df['min_query'], pd.rolling_sum, window=3)\n",
    "    df['last_5_sum_user'] = rolling(df['min_query'], pd.rolling_sum, window=5)\n",
    "    df['last_10_sum_user'] = rolling(df['min_query'], pd.rolling_sum, window=10)\n",
    "    df['last_15_sum_user'] = rolling(df['min_query'], pd.rolling_sum, window=15)\n",
    "    \n",
    "    new = pd.concat([new, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min15_click_all = pd.DataFrame()\n",
    "for index, row in data.iterrows():\n",
    "    print(index)\n",
    "    start_date = row['min_lab'] - 15\n",
    "    user_id = row['user_id']\n",
    "    shop_id = row['shop_id']\n",
    "    gap_data = data[(data.min_lab > start_date) & (data.min_lab <= row['min_lab'])]\n",
    "    gap_data = gap_data[(gap_data.user_id == user_id) & (gap_data.shop_id == shop_id)]\n",
    "    min15_click = gap_data.groupby(['user_id', 'shop_id']).size().reset_index().rename(columns={0:'min15_user_shop_click'})\n",
    "    min15_click_all = pd.concat([min15_click_all, min15_click], axis=0)\n",
    "    min15_click_all = min15_click_all.reset_index(drop=True)\n",
    "min15_click_all = min15_click_all['min15_user_shop_click']\n",
    "data=pd.concat([data, min15_user_shop_click, 'left'], axis=1)\n",
    "print('min 15 len :%d' % (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['min10'] = data['min'] // 10\n",
    "data['min15'] = data['min'] // 15\n",
    "data['min30'] = data['min'] // 30\n",
    "data['min45'] = data['min'] // 45\n",
    "\n",
    "min10_user_click = data.groupby(['user_id', 'min_10']).size().reset_index().rename(columns={0:'min10_user_click'})\n",
    "min15_user_click = data.groupby(['user_id', 'min_15']).size().reset_index().rename(columns={0:'min15_user_click'})\n",
    "min30_user_click = data.groupby(['user_id', 'min_30']).size().reset_index().rename(columns={0:'min30_user_click'})\n",
    "min45_user_click = data.groupby(['user_id', 'min_45']).size().reset_index().rename(columns={0:'min45_user_click'})\n",
    "\n",
    "data = pd.merge(data, min10_user_click, 'left', on=['user_id', 'min_10'])\n",
    "data = pd.merge(data, min15_user_click, 'left', on=['user_id', 'min_15'])\n",
    "data = pd.merge(data, min30_user_click, 'left', on=['user_id', 'min_30'])\n",
    "data = pd.merge(data, min45_user_click, 'left', on=['user_id', 'min_45'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/final_test_04-30-22-11.csv\")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = test.columns.tolist()\n",
    "for c in cols:\n",
    "    print(c)\n",
    "    print(test[[c]].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time'] = pd.to_datetime(data.context_timestamp, unit='s')\n",
    "data['time'] = data['time'].apply(lambda x: x + datetime.timedelta(hours=8))\n",
    "data['day'] = data['time'].apply(lambda x: int(str(x)[8:10]))\n",
    "data['hour'] = data['time'].apply(lambda x: int(str(x)[11:13])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_query = data.groupby(['day', 'hour', 'minute'], as_index=False)['item_collected_level'].agg({'hour_query_collect': 'sum'})\n",
    "pv_query = data.groupby(['day', 'hour', 'minute'], as_index=False)['item_pv_level'].agg({'hour_query_pv': 'sum'})\n",
    "sales_query = data.groupby(['day', 'hour', 'minute'], as_index=False)['item_sales_level'].agg({'hour_query_sales': 'sum'})\n",
    "trade_cnt = data.groupby(['day', 'hour', 'minute'], as_index=False)['is_trade'].agg({'click': 'count'})\n",
    "istrade_cnt = data.groupby(['day', 'hour', 'minute'], as_index=False)['is_trade'].agg({'trade': 'sum'})\n",
    "\n",
    "coll_query = coll_query.merge(pv_query, how='left', on=['day', 'hour', 'minute'])\n",
    "coll_query = coll_query.merge(sales_query, how='left', on=['day', 'hour', 'minute'])\n",
    "coll_query = coll_query.merge(trade_cnt, how='left', on=['day', 'hour', 'minute'])\n",
    "coll_query = coll_query.merge(istrade_cnt, how='left', on=['day', 'hour', 'minute'])\n",
    "\n",
    "coll_query['coll_sales'] = round(coll_query['hour_query_collect'] / coll_query['hour_query_sales'],4)\n",
    "coll_query['pv_sales'] = round(coll_query['hour_query_pv'] / coll_query['hour_query_sales'], 4)\n",
    "coll_query['ctr'] = round(coll_query['trade'] / coll_query['click'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['shop_score_service'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.user_id==419885]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = coll_query.loc[coll_query.hour==0]\n",
    "line = plt.plot(range(len(temp)),temp['ctr'],label=u'ctr')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = coll_query.loc[coll_query.hour==1]\n",
    "line = plt.plot(range(len(temp)),temp['ctr'],label=u'ctr')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = coll_query.loc[coll_query.hour==2]\n",
    "line = plt.plot(range(len(temp)),temp['hour_query_pv'],label=u'hour_query_pv')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pv_query.loc[pv_query.hour==11]\n",
    "line = plt.plot(range(len(temp)),temp['hour_query_pv'],label=u'hour_query_pv')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pv_query.loc[pv_query.hour==0]\n",
    "line = plt.plot(range(len(temp)),temp['hour_query_pv'],label=u'hour_query_pv')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = plt.plot(range(len(data)), (data['hour_query_price']),label=u'price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_select(train, test):\n",
    "\n",
    "    #去除全局特征instance_id, context_id, user_id\n",
    "    features = train.drop(['is_trade', 'instance_id', 'time', 'context_timestamp'], axis=1).columns.tolist()   \n",
    "    target = ['is_trade']\n",
    "\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model():\n",
    "\n",
    "    print('LGBMClassifier...')\n",
    "    clf = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=29, max_depth=-1, learning_rate=0.1, n_estimators=100,\n",
    "                               max_bin=425, subsample_for_bin=50000, objective='binary', min_split_gain=0,\n",
    "                               min_child_weight=5, min_child_samples=10, subsample=1, subsample_freq=1,\n",
    "                               colsample_bytree=1, reg_alpha=3, reg_lambda=5, seed=1000, nthread=-1, silent=True)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:train.shape[0]]\n",
    "test = data[train.shape[0]:]\n",
    "del data\n",
    "gc.collect()\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_feat(now_feature, train, test):\n",
    "    features, target = feat_select(train, test)\n",
    "\n",
    "    train_x = train.loc[(train.day < 24) & (train.day > 18)]# 19,20,21,22,23\n",
    "    test_x = train.loc[train.day == 24]\n",
    "    \n",
    "    clf = lgb_model()\n",
    "    \n",
    "    clf.fit(train_x[now_feature], train_x[target])\n",
    "    test_x['lgb_predict'] = clf.predict_proba(test_x[now_feature])[:, 1]\n",
    "    res = log_loss(test_x[target], test_x['lgb_predict'])\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正向搜索\n",
    "features, target = feat_select(train, test)\n",
    "now_feature = []\n",
    "check = 100\n",
    "le = len(features)\n",
    "for i in range(le):\n",
    "    now_feature.append(features[i])\n",
    "    jj = find_best_feat(now_feature, train, test)\n",
    "    if (jj<check)&(check-jj>0.00003):\n",
    "        print('目前特征长度为',len(now_feature),' 目前帅气的logloss值是',jj,' 成功加入第',i+1,'个','降低为',check-jj)\n",
    "        check = jj\n",
    "    else:\n",
    "        now_feature.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#反向搜索\n",
    "features, target = feat_select(train, test)\n",
    "now_feature_1 = []\n",
    "check = 100\n",
    "le = len(features)\n",
    "for i in range(le):\n",
    "    now_feature_1.append(features[le-1-i])\n",
    "    jj = find_best_feat(now_feature_1, train, test)\n",
    "    if (jj<check)&(check-jj>0.00003):\n",
    "        print('目前特征长度为',len(now_feature_1),' 目前帅气的logloss值是',jj,' 成功加入第',i+1,'个','降低为',check-jj)\n",
    "        check = jj\n",
    "    else:\n",
    "        now_feature_1.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#随机选取特征进行搜索\n",
    "import random\n",
    "feat, target = feat_select(train, test)\n",
    "le = len(feat)\n",
    "m = le \n",
    "del_feat = []\n",
    "s = 0\n",
    "while(s<10):\n",
    "    print('------------------------第',s+1,'轮-------------------------')\n",
    "    features, target = feat_select(train, test)\n",
    "    temp = []\n",
    "    check = 0.1\n",
    "    m = le\n",
    "    for i in range(le):\n",
    "        n = random.randint(0, m-1)\n",
    "        temp.append(features[n])\n",
    "        jj = find_best_feat(temp, train, test)\n",
    "        if (jj<check)&(check-jj>0.00003):\n",
    "            print('目前特征长度为',len(temp),' 目前帅气的logloss值是',jj,' 成功加入第',i+1,'个','降低为',check-jj)\n",
    "            check = jj\n",
    "            del_feat.append(features[n])\n",
    "        else:\n",
    "            temp.pop()\n",
    "        features.remove(features[n])\n",
    "        m -= 1\n",
    "    s += 1\n",
    "    for f in del_feat:\n",
    "        if f in feat:\n",
    "            feat.remove(f)\n",
    "    print('---------------------剩余特征',len(feat),'个-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从中间开始搜索\n",
    "features, target = feat_select(train, test)\n",
    "now_feature_3 = []\n",
    "check = 100\n",
    "le = len(features)\n",
    "lo = int(le/2)\n",
    "hi = lo + 1\n",
    "j = 0\n",
    "for i in range(int(le/2)):\n",
    "    if(lo >= 0):\n",
    "        now_feature_3.append(features[lo])\n",
    "        jj = find_best_feat(now_feature_3, train, test)\n",
    "        if (jj<check)&(check-jj>0.00003):\n",
    "            print('目前特征长度为',len(now_feature_3),' 目前帅气的logloss值是',jj,' 成功加入第',j+1,'个','降低为',check-jj)\n",
    "            check = jj\n",
    "        else:\n",
    "            now_feature_3.pop()\n",
    "        lo -= 1\n",
    "        j += 1\n",
    "    if(hi < le):\n",
    "        now_feature_3.append(features[hi])\n",
    "        jj = find_best_feat(now_feature_3, train, test)\n",
    "        if (jj<check)&(check-jj>0.00003):\n",
    "            print('目前特征长度为',len(now_feature_3),' 目前帅气的logloss值是',jj,' 成功加入第',j+1,'个','降低为',check-jj)\n",
    "            check = jj\n",
    "        else:\n",
    "            now_feature_3.pop()\n",
    "        hi += 1\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = now_feature + now_feature_1 + now_feature_2 + now_feature_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#小号保存\n",
    "li = set(li)\n",
    "li = list(li)\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_best_feat(features, train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = feat_select(train, test)\n",
    "for f in feat:\n",
    "    if(f in features):\n",
    "        features.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "a = [[0.000125, 2, 3, 4, 5],\n",
    "     [1, 2, 3, 4, 5],\n",
    "     [1, 2, 3, 4, 5]\n",
    "    ]\n",
    "numpy.savetxt('arr.txt',a)\n",
    "b = numpy.loadtxt('arr.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = numpy.loadtxt('arr.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
